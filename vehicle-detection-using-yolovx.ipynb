{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8773960,"sourceType":"datasetVersion","datasetId":5273103}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ultralytics optuna pyyaml","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-24T12:43:01.836646Z","iopub.execute_input":"2024-06-24T12:43:01.837024Z","iopub.status.idle":"2024-06-24T12:43:14.299183Z","shell.execute_reply.started":"2024-06-24T12:43:01.836994Z","shell.execute_reply":"2024-06-24T12:43:14.298146Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: ultralytics in /opt/conda/lib/python3.10/site-packages (8.2.41)\nRequirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (3.6.1)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (6.0.1)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.10.0.82)\nRequirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.5.0)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.11.4)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.1.2)\nRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.16.2)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.2.1)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\nRequirement already satisfied: ultralytics-thop>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.0.0)\nRequirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (1.13.1)\nRequirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna) (6.8.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (21.3)\nRequirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (2.0.25)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.5)\nRequirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.9.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.3.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from ultralytics import YOLO\nimport optuna\nimport os\nimport yaml","metadata":{"execution":{"iopub.status.busy":"2024-06-24T12:43:14.301151Z","iopub.execute_input":"2024-06-24T12:43:14.301543Z","iopub.status.idle":"2024-06-24T12:43:16.400024Z","shell.execute_reply.started":"2024-06-24T12:43:14.301483Z","shell.execute_reply":"2024-06-24T12:43:16.398793Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Set this environment variable to disable strict metric checking\nos.environ['TUNE_DISABLE_STRICT_METRIC_CHECKING'] = '1'","metadata":{"execution":{"iopub.status.busy":"2024-06-24T12:43:16.401277Z","iopub.execute_input":"2024-06-24T12:43:16.401714Z","iopub.status.idle":"2024-06-24T12:43:16.406000Z","shell.execute_reply.started":"2024-06-24T12:43:16.401684Z","shell.execute_reply":"2024-06-24T12:43:16.404913Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def train_yolov8(trial):\n    model = YOLO(\"yolov8x.pt\")  # Load a pretrained YOLOv8 model\n\n    # Set up the dataset path\n    data_path = \"/kaggle/input/vehicle-detection/data.yaml\"  # Replace with your dataset path\n    print(f\"Training on dataset: {data_path}\")\n\n    # Suggest hyperparameters\n    config = {\n        \"epochs\": trial.suggest_int(\"epochs\", 5, 20),\n        \"batch_size\": trial.suggest_categorical(\"batch_size\", [8, 16, 32]),\n        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3),\n        \"image_size\": trial.suggest_categorical(\"image_size\", [640, 720, 800])\n    }\n\n    print(f\"Starting training with config: {config}\")\n\n    results = model.train(\n        data=data_path,\n        epochs=config[\"epochs\"],\n        batch=config[\"batch_size\"],\n        lr0=config[\"learning_rate\"],\n        imgsz=config[\"image_size\"]\n    )\n\n    print(\"Training completed, extracting metrics...\")\n\n    # Extract validation metrics\n    metrics = results.results_dict\n    print(f\"Validation metrics: {metrics}\")\n\n    # Print results per class\n    with open(data_path, 'r') as f:\n        data_dict = yaml.safe_load(f)\n    class_names = data_dict['names']\n\n    # Return the metric to be optimized\n    return metrics['metrics/mAP50-95(B)']","metadata":{"execution":{"iopub.status.busy":"2024-06-24T12:43:16.407889Z","iopub.execute_input":"2024-06-24T12:43:16.408235Z","iopub.status.idle":"2024-06-24T12:43:16.418685Z","shell.execute_reply.started":"2024-06-24T12:43:16.408210Z","shell.execute_reply":"2024-06-24T12:43:16.417919Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n    return train_yolov8(trial)","metadata":{"execution":{"iopub.status.busy":"2024-06-24T12:43:16.419746Z","iopub.execute_input":"2024-06-24T12:43:16.420068Z","iopub.status.idle":"2024-06-24T12:43:16.429968Z","shell.execute_reply.started":"2024-06-24T12:43:16.420037Z","shell.execute_reply":"2024-06-24T12:43:16.429120Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    study = optuna.create_study(direction=\"maximize\")\n    study.optimize(objective, n_trials=20)\n\n    print(\"Best trial:\")\n    trial = study.best_trial\n    print(f\"  Value: {trial.value}\")\n    print(\"  Params: \")\n    for key, value in trial.params.items():\n        print(f\"    {key}: {value}\")\n\n    # Train the model with the best hyperparameters\n    best_model = YOLO(\"yolov8x.pt\")\n    best_results = best_model.train(\n        data=\"/content/drive/MyDrive/dataset/data.yaml\",\n        epochs=trial.params[\"epochs\"],\n        batch=trial.params[\"batch_size\"],\n        lr0=trial.params[\"learning_rate\"],\n        imgsz=trial.params[\"image_size\"]\n    )\n\n    print(\"\\nFinal results with best hyperparameters:\")\n    print(best_results)","metadata":{"execution":{"iopub.status.busy":"2024-06-24T12:43:16.430943Z","iopub.execute_input":"2024-06-24T12:43:16.431225Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"[I 2024-06-24 12:43:16,437] A new study created in memory with name: no-name-b0109c21-83da-4272-8aa6-2a94ddd037b6\n","output_type":"stream"},{"name":"stdout","text":"Training on dataset: /kaggle/input/vehicle-detection/data.yaml\nStarting training with config: {'epochs': 6, 'batch_size': 8, 'learning_rate': 0.0001061599971707366, 'image_size': 720}\nUltralytics YOLOv8.2.41 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=/kaggle/input/vehicle-detection/data.yaml, epochs=6, time=None, patience=100, batch=8, imgsz=720, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.0001061599971707366, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_110/921516691.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3),\n2024-06-24 12:43:17,192\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n2024-06-24 12:43:18,041\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n","output_type":"stream"},{"name":"stdout","text":"Overriding model.yaml nc=80 with nc=15\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n 22        [15, 18, 21]  1   8732413  ultralytics.nn.modules.head.Detect           [15, [320, 640, 640]]         \nModel summary: 365 layers, 68167053 parameters, 68167037 gradients, 258.2 GFLOPs\n\nTransferred 589/595 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ·\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m API key must be 40 characters long, yours was 1\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240624_124623-ekkyf7n2</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/akhileshts17/YOLOv8/runs/ekkyf7n2' target=\"_blank\">train2</a></strong> to <a href='https://wandb.ai/akhileshts17/YOLOv8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/akhileshts17/YOLOv8' target=\"_blank\">https://wandb.ai/akhileshts17/YOLOv8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/akhileshts17/YOLOv8/runs/ekkyf7n2' target=\"_blank\">https://wandb.ai/akhileshts17/YOLOv8/runs/ekkyf7n2</a>"},"metadata":{}},{"name":"stdout","text":"Freezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\nDownloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 6.23M/6.23M [00:00<00:00, 78.5MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\nWARNING ⚠️ imgsz=[720] must be multiple of max stride 32, updating to [736]\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/vehicle-detection/train/labels... 2600 images, 2 backgrounds, 0 corrupt: 100%|██████████| 2600/2600 [00:07<00:00, 352.95it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/vehicle-detection/train/images/rainy day (236).jpg: 1 duplicate labels removed\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ Cache directory /kaggle/input/vehicle-detection/train is not writeable, cache not saved.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/vehicle-detection/val/labels... 200 images, 0 backgrounds, 0 corrupt: 100%|██████████| 200/200 [00:00<00:00, 341.45it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ Cache directory /kaggle/input/vehicle-detection/val is not writeable, cache not saved.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to runs/detect/train2/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.0001061599971707366' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000526, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\nImage sizes 736 train, 736 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mruns/detect/train2\u001b[0m\nStarting training for 6 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        1/6       9.9G      1.812      1.598       1.46         60        736: 100%|██████████| 325/325 [04:30<00:00,  1.20it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  1.90it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        200       1199      0.309      0.324      0.323      0.144\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        2/6      9.55G      1.817      1.318      1.498         97        736: 100%|██████████| 325/325 [04:27<00:00,  1.21it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.34it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        200       1199      0.466      0.367      0.361      0.173\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        3/6      9.86G      1.803      1.209      1.496         47        736: 100%|██████████| 325/325 [04:26<00:00,  1.22it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.34it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        200       1199      0.585      0.342      0.433      0.213\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        4/6      9.53G      1.742      1.092      1.459        134        736: 100%|██████████| 325/325 [04:26<00:00,  1.22it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.36it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        200       1199       0.57      0.472      0.531      0.264\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        5/6      9.81G      1.701     0.9673      1.434        104        736: 100%|██████████| 325/325 [04:26<00:00,  1.22it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.35it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        200       1199      0.569      0.512      0.551      0.273\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        6/6      9.81G      1.629     0.8679      1.391        107        736: 100%|██████████| 325/325 [04:26<00:00,  1.22it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:05<00:00,  2.36it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        200       1199      0.763      0.482      0.607      0.302\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n6 epochs completed in 0.463 hours.\nOptimizer stripped from runs/detect/train2/weights/last.pt, 136.7MB\nOptimizer stripped from runs/detect/train2/weights/best.pt, 136.7MB\n\nValidating runs/detect/train2/weights/best.pt...\nUltralytics YOLOv8.2.41 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\nModel summary (fused): 268 layers, 68138013 parameters, 0 gradients, 257.5 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:12<00:00,  1.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all        200       1199      0.763      0.482      0.607      0.302\n                   car        159        743      0.856      0.841      0.882      0.449\n                  bike         99        125      0.623      0.784      0.793      0.402\n                  auto         47         60      0.902      0.307      0.548      0.234\n                 cycle         29         46      0.481       0.13      0.184     0.0965\n                   bus         48         52      0.895      0.673      0.756      0.293\n             minitruck         54         58      0.659      0.362      0.381      0.193\n                 truck         32         47      0.794      0.617      0.733      0.347\n                   van         25         28      0.455      0.107      0.208      0.122\n                  taxi         10         10      0.961          1      0.995      0.603\n                  toto         28         30          1          0      0.592      0.281\nSpeed: 0.2ms preprocess, 23.7ms inference, 0.0ms loss, 1.0ms postprocess per image\nResults saved to \u001b[1mruns/detect/train2\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='136.185 MB of 136.185 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>▃▆█▆▃▁</td></tr><tr><td>lr/pg1</td><td>▃▆█▆▃▁</td></tr><tr><td>lr/pg2</td><td>▃▆█▆▃▁</td></tr><tr><td>metrics/mAP50(B)</td><td>▁▂▄▆▇█</td></tr><tr><td>metrics/mAP50-95(B)</td><td>▁▂▄▆▇█</td></tr><tr><td>metrics/precision(B)</td><td>▁▃▅▅▅█</td></tr><tr><td>metrics/recall(B)</td><td>▁▃▂▇█▇</td></tr><tr><td>model/GFLOPs</td><td>▁</td></tr><tr><td>model/parameters</td><td>▁</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>▁</td></tr><tr><td>train/box_loss</td><td>███▅▄▁</td></tr><tr><td>train/cls_loss</td><td>█▅▄▃▂▁</td></tr><tr><td>train/dfl_loss</td><td>▅██▅▄▁</td></tr><tr><td>val/box_loss</td><td>█▆▆▄▂▁</td></tr><tr><td>val/cls_loss</td><td>█▇▇▃▂▁</td></tr><tr><td>val/dfl_loss</td><td>█▆█▄▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>9e-05</td></tr><tr><td>lr/pg1</td><td>9e-05</td></tr><tr><td>lr/pg2</td><td>9e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.60729</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.3021</td></tr><tr><td>metrics/precision(B)</td><td>0.76267</td></tr><tr><td>metrics/recall(B)</td><td>0.48215</td></tr><tr><td>model/GFLOPs</td><td>258.198</td></tr><tr><td>model/parameters</td><td>68167053</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>23.817</td></tr><tr><td>train/box_loss</td><td>1.62908</td></tr><tr><td>train/cls_loss</td><td>0.86792</td></tr><tr><td>train/dfl_loss</td><td>1.39117</td></tr><tr><td>val/box_loss</td><td>1.70233</td></tr><tr><td>val/cls_loss</td><td>1.21079</td></tr><tr><td>val/dfl_loss</td><td>1.56855</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">train2</strong> at: <a href='https://wandb.ai/akhileshts17/YOLOv8/runs/ekkyf7n2' target=\"_blank\">https://wandb.ai/akhileshts17/YOLOv8/runs/ekkyf7n2</a><br/> View project at: <a href='https://wandb.ai/akhileshts17/YOLOv8' target=\"_blank\">https://wandb.ai/akhileshts17/YOLOv8</a><br/>Synced 5 W&B file(s), 21 media file(s), 5 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240624_124623-ekkyf7n2/logs</code>"},"metadata":{}},{"name":"stderr","text":"[I 2024-06-24 13:15:27,231] Trial 0 finished with value: 0.3020971245519896 and parameters: {'epochs': 6, 'batch_size': 8, 'learning_rate': 0.0001061599971707366, 'image_size': 720}. Best is trial 0 with value: 0.3020971245519896.\n","output_type":"stream"},{"name":"stdout","text":"Training completed, extracting metrics...\nValidation metrics: {'metrics/precision(B)': 0.762669584169629, 'metrics/recall(B)': 0.4821519280183798, 'metrics/mAP50(B)': 0.6072904115320263, 'metrics/mAP50-95(B)': 0.3020971245519896, 'fitness': 0.33261645324999334}\nTraining on dataset: /kaggle/input/vehicle-detection/data.yaml\nStarting training with config: {'epochs': 16, 'batch_size': 8, 'learning_rate': 2.808866376913121e-05, 'image_size': 800}\nUltralytics YOLOv8.2.41 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=/kaggle/input/vehicle-detection/data.yaml, epochs=16, time=None, patience=100, batch=8, imgsz=800, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=2.808866376913121e-05, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train3\nOverriding model.yaml nc=80 with nc=15\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n 22        [15, 18, 21]  1   8732413  ultralytics.nn.modules.head.Detect           [15, [320, 640, 640]]         \nModel summary: 365 layers, 68167053 parameters, 68167037 gradients, 258.2 GFLOPs\n\nTransferred 589/595 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train3', view at http://localhost:6006/\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtsakhilesh12\u001b[0m (\u001b[33makhileshts17\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240624_131529-2d0ycm6t</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/akhileshts17/YOLOv8/runs/2d0ycm6t' target=\"_blank\">train3</a></strong> to <a href='https://wandb.ai/akhileshts17/YOLOv8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/akhileshts17/YOLOv8' target=\"_blank\">https://wandb.ai/akhileshts17/YOLOv8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/akhileshts17/YOLOv8/runs/2d0ycm6t' target=\"_blank\">https://wandb.ai/akhileshts17/YOLOv8/runs/2d0ycm6t</a>"},"metadata":{}},{"name":"stdout","text":"Freezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/vehicle-detection/train/labels... 2600 images, 2 backgrounds, 0 corrupt: 100%|██████████| 2600/2600 [00:02<00:00, 1094.44it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/vehicle-detection/train/images/rainy day (236).jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ Cache directory /kaggle/input/vehicle-detection/train is not writeable, cache not saved.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/vehicle-detection/val/labels... 200 images, 0 backgrounds, 0 corrupt: 100%|██████████| 200/200 [00:00<00:00, 958.34it/s] ","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ Cache directory /kaggle/input/vehicle-detection/val is not writeable, cache not saved.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to runs/detect/train3/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=2.808866376913121e-05' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000526, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\nImage sizes 800 train, 800 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mruns/detect/train3\u001b[0m\nStarting training for 16 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       1/16        12G      1.823      1.635      1.486         61        800: 100%|██████████| 325/325 [05:17<00:00,  1.02it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  2.02it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        200       1199      0.223      0.354      0.258      0.112\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       2/16      11.1G      1.836      1.362      1.528         97        800: 100%|██████████| 325/325 [05:12<00:00,  1.04it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  2.03it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        200       1199      0.365      0.342       0.36      0.147\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       3/16      11.4G       1.84      1.313      1.523         47        800: 100%|██████████| 325/325 [05:11<00:00,  1.04it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  2.04it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        200       1199      0.409      0.232      0.261      0.109\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       4/16      11.1G       1.81      1.241       1.51        134        800: 100%|██████████| 325/325 [05:10<00:00,  1.05it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  2.04it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        200       1199      0.526      0.344      0.402        0.2\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       5/16      11.3G      1.788      1.142      1.501        104        800: 100%|██████████| 325/325 [05:10<00:00,  1.05it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  2.03it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        200       1199       0.56      0.374      0.421       0.19\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       6/16      11.3G      1.743      1.057      1.466        107        800: 100%|██████████| 325/325 [05:10<00:00,  1.05it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  2.04it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        200       1199      0.519      0.433       0.49      0.228\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Closing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       7/16      11.3G      1.763      1.015      1.519         78        800: 100%|██████████| 325/325 [05:10<00:00,  1.05it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  2.03it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        200       1199       0.48      0.409      0.444      0.224\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       8/16      11.3G      1.747     0.9635      1.518         53        800: 100%|██████████| 325/325 [05:09<00:00,  1.05it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  2.03it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        200       1199      0.525      0.423      0.462       0.24\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       9/16      11.3G      1.729     0.9184      1.497         60        800: 100%|██████████| 325/325 [05:09<00:00,  1.05it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 13/13 [00:06<00:00,  2.04it/s]","output_type":"stream"},{"name":"stdout","text":"                   all        200       1199       0.53      0.439      0.474      0.233\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      10/16      11.3G      1.703     0.8788      1.472         41        800:  86%|████████▋ | 281/325 [04:28<00:41,  1.05it/s]","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]}]}